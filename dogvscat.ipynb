{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Dog Cat Classification","metadata":{}},{"cell_type":"markdown","source":"### 1 - Package import ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt\nimport os\nimport random\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as tfl\n\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-14T04:22:41.615351Z","iopub.execute_input":"2021-12-14T04:22:41.615691Z","iopub.status.idle":"2021-12-14T04:22:41.628121Z","shell.execute_reply.started":"2021-12-14T04:22:41.615655Z","shell.execute_reply":"2021-12-14T04:22:41.627134Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### 2 - Data Import","metadata":{}},{"cell_type":"code","source":"train_path = '../input/dogs-vs-cats/train.zip'\ntest_path = '../input/dogs-vs-cats/test1.zip'\n\ndestination = '/kaggle/files/images'\n\nfrom zipfile import ZipFile as zipper\nwith zipper(train_path, 'r') as zipp:\n    zipp.extractall(destination)\n    \nwith zipper(test_path, 'r') as zipp:\n    zipp.extractall(destination)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:22:41.633291Z","iopub.execute_input":"2021-12-14T04:22:41.634477Z","iopub.status.idle":"2021-12-14T04:22:58.731073Z","shell.execute_reply.started":"2021-12-14T04:22:41.634416Z","shell.execute_reply":"2021-12-14T04:22:58.730306Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train = pd.DataFrame({'file': os.listdir('/kaggle/files/images/train')})\n\ncategories = []\nfor i in os.listdir('/kaggle/files/images/train'):\n    if 'dog' in i:\n        categories.append(1)\n    else:\n        categories.append(0)\n        \ntrain['categories'] = categories\n\ntest = pd.DataFrame({'file': os.listdir('/kaggle/files/images/test1')})","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:22:58.732578Z","iopub.execute_input":"2021-12-14T04:22:58.732837Z","iopub.status.idle":"2021-12-14T04:22:58.800901Z","shell.execute_reply.started":"2021-12-14T04:22:58.732802Z","shell.execute_reply":"2021-12-14T04:22:58.800091Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### 3 - See an example ","metadata":{}},{"cell_type":"code","source":"def example_im(index):\n    '''\n    Function to display an example image.\n    \n    index -- which image in the training set. \n    '''\n    im = plt.imread('/kaggle/files/images/train/'+str(train['file'][index]))\n\n    print(type(im))\n    print(im.shape)\n    print(type(im.shape))\n    \n    plt.imshow(im)\n    plt.axis('off')\nexample_im(1)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:22:58.805217Z","iopub.execute_input":"2021-12-14T04:22:58.805421Z","iopub.status.idle":"2021-12-14T04:22:59.177990Z","shell.execute_reply.started":"2021-12-14T04:22:58.805396Z","shell.execute_reply":"2021-12-14T04:22:59.177119Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### 4 - Data Preparation ","metadata":{}},{"cell_type":"code","source":"train['categories'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:22:59.179388Z","iopub.execute_input":"2021-12-14T04:22:59.184648Z","iopub.status.idle":"2021-12-14T04:22:59.192471Z","shell.execute_reply.started":"2021-12-14T04:22:59.184597Z","shell.execute_reply":"2021-12-14T04:22:59.191518Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"For our data, we have same number of cats and dogs and training data.","metadata":{}},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:22:59.193973Z","iopub.execute_input":"2021-12-14T04:22:59.194289Z","iopub.status.idle":"2021-12-14T04:22:59.203269Z","shell.execute_reply.started":"2021-12-14T04:22:59.194248Z","shell.execute_reply":"2021-12-14T04:22:59.202430Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"The numeric varaible in `categories` columns is mapped to string for later image generation\n\nThe training data is not a particularly small dataset so we can use `10%` of its data as a `cross validation set`, and `random_state` is set to be 0 for reproductivity.","metadata":{}},{"cell_type":"code","source":"train['categories'] = train['categories'].replace({0: 'cat', 1: 'dog'})\ntrain_set, val_set = train_test_split(train, test_size=0.1, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:22:59.204654Z","iopub.execute_input":"2021-12-14T04:22:59.205136Z","iopub.status.idle":"2021-12-14T04:22:59.220325Z","shell.execute_reply.started":"2021-12-14T04:22:59.204980Z","shell.execute_reply":"2021-12-14T04:22:59.219269Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_gen = ImageDataGenerator(rescale=1./255)\nval_gen = ImageDataGenerator(rescale=1./255)\n\nbatch_size = 64\n\ntrain_generator = train_gen.flow_from_dataframe(\n    dataframe = train_set,\n    directory = destination + '/train/', # file path format\n    x_col = 'file',\n    y_col = 'categories',\n    class_mode = 'categorical',\n    target_size = (224,224),\n    batch_size = batch_size\n)\n\n\nvalidation_generator = val_gen.flow_from_dataframe(\n    dataframe = val_set,\n    directory = destination + '/train/',\n    x_col = 'file',\n    y_col = 'categories',\n    class_mode = 'categorical',\n    target_size = (224,224),\n    batch_size = batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:22:59.222730Z","iopub.execute_input":"2021-12-14T04:22:59.222943Z","iopub.status.idle":"2021-12-14T04:22:59.505945Z","shell.execute_reply.started":"2021-12-14T04:22:59.222918Z","shell.execute_reply":"2021-12-14T04:22:59.505153Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def mini_batch_example_plot(df):\n\n    example_generator = train_gen.flow_from_dataframe(\n        dataframe = df,\n        directory = destination + '/train/',\n        x_col = 'file',\n        y_col = 'categories',\n        class_mode = 'categorical',\n        target_size = (224,224)\n    )\n    \n    fig, ax  = plt.subplots(2,4,figsize=(12, 12))\n    ax = ax.flatten()\n    \n    for i in range(8):\n        X, Y = next(example_generator)\n        image = X[0]\n        ax[i].imshow(image)\n        ax[i].axis('off')\n    \n    \nmini_batch_example_plot(train_set)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:22:59.507221Z","iopub.execute_input":"2021-12-14T04:22:59.508136Z","iopub.status.idle":"2021-12-14T04:23:00.926779Z","shell.execute_reply.started":"2021-12-14T04:22:59.508092Z","shell.execute_reply":"2021-12-14T04:23:00.925884Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### 5 - CNN model construction","metadata":{}},{"cell_type":"code","source":"from numpy.random import seed\nseed(1)\n\ntf.random.set_seed(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:45:34.811958Z","iopub.execute_input":"2021-12-14T05:45:34.812512Z","iopub.status.idle":"2021-12-14T05:45:34.831549Z","shell.execute_reply.started":"2021-12-14T05:45:34.812471Z","shell.execute_reply":"2021-12-14T05:45:34.830740Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import (\n    BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n)\n\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\n","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:23:00.929622Z","iopub.execute_input":"2021-12-14T04:23:00.930095Z","iopub.status.idle":"2021-12-14T04:23:00.938241Z","shell.execute_reply.started":"2021-12-14T04:23:00.930060Z","shell.execute_reply":"2021-12-14T04:23:00.934806Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# set constants\n(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS) = (224,224,3)\nIMAGE_SIZE  = (IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_SHAPE = (224,224,3)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:23:00.939177Z","iopub.execute_input":"2021-12-14T04:23:00.939355Z","iopub.status.idle":"2021-12-14T04:23:00.951177Z","shell.execute_reply.started":"2021-12-14T04:23:00.939333Z","shell.execute_reply":"2021-12-14T04:23:00.950464Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def shallow_CNN_Model(image_shape, augmentation = False):\n    '''\n    This creates a shallow CNN model, the structure uses the idea from VGG-16\n    '''\n    if (augmentation == True):\n        model = tf.keras.Sequential([RandomFlip(\"horizontal\",input_shape = image_shape),\n                   RandomRotation(0.1)])\n    else: \n        model = tf.keras.Sequential()\n\n    model.add(Conv2D(32, (3, 3), activation='relu', input_shape = image_shape))\n    model.add(Conv2D(32, (3, 3), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation='softmax'))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:23:00.952323Z","iopub.execute_input":"2021-12-14T04:23:00.952625Z","iopub.status.idle":"2021-12-14T04:23:01.155868Z","shell.execute_reply.started":"2021-12-14T04:23:00.952599Z","shell.execute_reply":"2021-12-14T04:23:01.155086Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model = shallow_CNN_Model(IMAGE_SHAPE)\nmodel_augmented = shallow_CNN_Model(IMAGE_SHAPE,True)\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_augmented.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:23:01.157113Z","iopub.execute_input":"2021-12-14T04:23:01.157567Z","iopub.status.idle":"2021-12-14T04:23:01.496827Z","shell.execute_reply.started":"2021-12-14T04:23:01.157517Z","shell.execute_reply":"2021-12-14T04:23:01.495856Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### 6 - Early stopping after seeing no decrease in loss over 5 epoches","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nearlystop = EarlyStopping(patience=5)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:23:01.498081Z","iopub.execute_input":"2021-12-14T04:23:01.498359Z","iopub.status.idle":"2021-12-14T04:23:01.504045Z","shell.execute_reply.started":"2021-12-14T04:23:01.498311Z","shell.execute_reply":"2021-12-14T04:23:01.502984Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def model_fitting(model, callbacks, epochs):\n    '''\n    This is a function used to fit generator, with customized input \n    model, callbacks, and epochs. \n    '''\n    return model.fit_generator(\n        train_generator, \n        epochs = epochs,\n        validation_data = validation_generator,\n        validation_steps = val_set.shape[0]//64,\n        steps_per_epoch = train_set.shape[0]//64,\n        callbacks = callbacks \n    )\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:23:01.505566Z","iopub.execute_input":"2021-12-14T04:23:01.505930Z","iopub.status.idle":"2021-12-14T04:23:01.514309Z","shell.execute_reply.started":"2021-12-14T04:23:01.505783Z","shell.execute_reply":"2021-12-14T04:23:01.513492Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"In previous test, the dataset not being augmented performs worse than augmented dataset on validation set, showing a sign of overfitting in training set.  ","metadata":{}},{"cell_type":"code","source":"# history_epoch50 = model_fitting(model, [earlystop], epochs = 50)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:23:01.515394Z","iopub.execute_input":"2021-12-14T04:23:01.515641Z","iopub.status.idle":"2021-12-14T04:23:01.527221Z","shell.execute_reply.started":"2021-12-14T04:23:01.515611Z","shell.execute_reply":"2021-12-14T04:23:01.526348Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"history_epoch50_augmented = model_fitting(model_augmented, [earlystop], epochs = 50)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:23:01.529750Z","iopub.execute_input":"2021-12-14T04:23:01.530719Z","iopub.status.idle":"2021-12-14T05:32:53.575627Z","shell.execute_reply.started":"2021-12-14T04:23:01.530677Z","shell.execute_reply":"2021-12-14T05:32:53.574890Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model_augmented.save_weights('model_augmented_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:38:05.152124Z","iopub.execute_input":"2021-12-14T05:38:05.153004Z","iopub.status.idle":"2021-12-14T05:38:05.493151Z","shell.execute_reply.started":"2021-12-14T05:38:05.152957Z","shell.execute_reply":"2021-12-14T05:38:05.492416Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"\ndef plotting_loss(history,upper_bound):\n\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 4))\n    ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n    ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n    ax1.set_xticks(np.arange(1, upper_bound, 1))\n    ax1.set_yticks(np.arange(0, 1, 0.1))\n\n    ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n    ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n    ax2.set_xticks(np.arange(1, upper_bound, 1))\n\n    legend = plt.legend(loc='best', shadow=True)\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:38:16.562290Z","iopub.execute_input":"2021-12-14T05:38:16.563079Z","iopub.status.idle":"2021-12-14T05:38:16.573177Z","shell.execute_reply.started":"2021-12-14T05:38:16.563040Z","shell.execute_reply":"2021-12-14T05:38:16.572340Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# plotting_loss(history_epoch50, 50)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:38:17.194987Z","iopub.execute_input":"2021-12-14T05:38:17.195688Z","iopub.status.idle":"2021-12-14T05:38:17.198851Z","shell.execute_reply.started":"2021-12-14T05:38:17.195650Z","shell.execute_reply":"2021-12-14T05:38:17.198157Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"plotting_loss(history_epoch50_augmented, 40)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:38:25.521363Z","iopub.execute_input":"2021-12-14T05:38:25.521940Z","iopub.status.idle":"2021-12-14T05:38:26.291035Z","shell.execute_reply.started":"2021-12-14T05:38:25.521895Z","shell.execute_reply":"2021-12-14T05:38:26.290323Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"Using functional API for easier operation on last few layers for transfer learning.","metadata":{}},{"cell_type":"code","source":"def data_augmenter():\n    '''\n    Create a Sequential model composed of 2 layers\n    Returns:\n        tf.keras.Sequential\n    '''\n    ### START CODE HERE\n    data_augmentation = tf.keras.Sequential()\n    data_augmentation.add(RandomFlip('horizontal'))\n    data_augmentation.add(RandomRotation(0.2))\n    ### END CODE HERE\n    \n    return data_augmentation","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:39:28.758307Z","iopub.execute_input":"2021-12-14T05:39:28.759175Z","iopub.status.idle":"2021-12-14T05:39:28.764727Z","shell.execute_reply.started":"2021-12-14T05:39:28.759134Z","shell.execute_reply":"2021-12-14T05:39:28.764015Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"input_shape = (224,224, 3)\npreprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n\ndef transfer_learning(model,image_shape=input_shape, data_augmentation=data_augmenter()):\n    ''' Define a tf.keras model for binary classification out of the MobileNetV2 model\n    Arguments:\n        image_shape -- Image width and height\n        data_augmentation -- data augmentation function\n\n    Returns:\n        tf.keras.model\n    '''\n    if model == 'MobileNetV2':\n        base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n                                                       include_top=False, \n                                                       weights='imagenet') # From imageNet\n    if model == 'VGG':\n        base_model = tf.keras.applications.VGG16(input_shape=input_shape,\n                                                    weights=\"imagenet\", \n                                                    include_top=False)\n\n    # freeze the base model by making it non trainable\n    base_model.trainable = False\n\n    # create the input layer (Same as the imageNetv2 input size)\n    inputs = tf.keras.Input(shape = input_shape) \n    \n    # apply data augmentation to the inputs\n    x = data_augmentation(inputs)\n    \n    # data preprocessing using the same weights the model was trained on\n    x = preprocess_input(x) \n    \n    # set training to False to avoid keeping track of statistics in the batch norm layer\n    x = base_model(x, training=False) \n    \n    # add the new Binary classification layers\n    # use global avg pooling to summarize the info in each channel\n    x = tfl.GlobalAveragePooling2D()(x) \n    # include dropout with probability of 0.2 to avoid overfitting\n    x = tfl.Dropout(0.2)(x)\n        \n    # use a prediction layer with one neuron (as a binary classifier only needs one)\n    outputs = tfl.Dense(units = 2)(x)\n\n    model = tf.keras.Model(inputs, outputs)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:56:32.988144Z","iopub.execute_input":"2021-12-14T05:56:32.988607Z","iopub.status.idle":"2021-12-14T05:56:33.007710Z","shell.execute_reply.started":"2021-12-14T05:56:32.988563Z","shell.execute_reply":"2021-12-14T05:56:33.006630Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"model_trans_VGG = transfer_learning('VGG',(224,224,3), data_augmenter())\nbase_learning_rate = 0.001\nmodel_trans_VGG.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel_trans_Mobile = transfer_learning('MobileNetV2',(224,224,3), data_augmenter())\nbase_learning_rate = 0.001\nmodel_trans_Mobile.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel_trans_VGG.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:56:36.663106Z","iopub.execute_input":"2021-12-14T05:56:36.663365Z","iopub.status.idle":"2021-12-14T05:56:38.485219Z","shell.execute_reply.started":"2021-12-14T05:56:36.663329Z","shell.execute_reply":"2021-12-14T05:56:38.484504Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"model_trans_Mobile.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:56:41.817992Z","iopub.execute_input":"2021-12-14T05:56:41.818897Z","iopub.status.idle":"2021-12-14T05:56:41.840351Z","shell.execute_reply.started":"2021-12-14T05:56:41.818854Z","shell.execute_reply":"2021-12-14T05:56:41.839187Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"history_trans_VGG = model_fitting(model_trans_VGG, [earlystop], epochs = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:56:43.922398Z","iopub.execute_input":"2021-12-14T05:56:43.923098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_trans_Mobile = model_fitting(model_trans_Mobile, [earlystop], epochs = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:53:07.608434Z","iopub.status.idle":"2021-12-14T05:53:07.610572Z","shell.execute_reply.started":"2021-12-14T05:53:07.610358Z","shell.execute_reply":"2021-12-14T05:53:07.610380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotting_loss(history_trans_VGG, 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:53:07.614095Z","iopub.status.idle":"2021-12-14T05:53:07.616404Z","shell.execute_reply.started":"2021-12-14T05:53:07.616164Z","shell.execute_reply":"2021-12-14T05:53:07.616189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotting_loss(history_trans_Mobile, 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T05:53:07.618923Z","iopub.status.idle":"2021-12-14T05:53:07.619518Z","shell.execute_reply.started":"2021-12-14T05:53:07.619280Z","shell.execute_reply":"2021-12-14T05:53:07.619302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fine-tuning the Model","metadata":{}},{"cell_type":"markdown","source":"Unfreeze the final layers and re-run the optimizer with a smaller learning rate, while keeping all the other layers frozen.\n\nUnfreeze the base model by setting `base_model.trainable=True`, set a layer to fine-tune from, then re-freeze all the layers before it.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsubmission(model_augmented)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}