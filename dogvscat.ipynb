{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Dog Cat Classification","metadata":{}},{"cell_type":"markdown","source":"### 1 - Package import ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt\nimport os\nimport random\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as tfl\n\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-14T19:18:07.600604Z","iopub.execute_input":"2021-12-14T19:18:07.601132Z","iopub.status.idle":"2021-12-14T19:18:13.403221Z","shell.execute_reply.started":"2021-12-14T19:18:07.601043Z","shell.execute_reply":"2021-12-14T19:18:13.402343Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from numpy.random import seed\nseed(1)\n\ntf.random.set_seed(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:13.404879Z","iopub.execute_input":"2021-12-14T19:18:13.405142Z","iopub.status.idle":"2021-12-14T19:18:13.411463Z","shell.execute_reply.started":"2021-12-14T19:18:13.405106Z","shell.execute_reply":"2021-12-14T19:18:13.409042Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### 2 - Data Import","metadata":{}},{"cell_type":"code","source":"train_path = '../input/dogs-vs-cats/train.zip'\ntest_path = '../input/dogs-vs-cats/test1.zip'\n\ndestination = '/kaggle/files/images'\n\nfrom zipfile import ZipFile as zipper\nwith zipper(train_path, 'r') as zipp:\n    zipp.extractall(destination)\n    \nwith zipper(test_path, 'r') as zipp:\n    zipp.extractall(destination)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:13.413314Z","iopub.execute_input":"2021-12-14T19:18:13.413580Z","iopub.status.idle":"2021-12-14T19:18:32.359769Z","shell.execute_reply.started":"2021-12-14T19:18:13.413544Z","shell.execute_reply":"2021-12-14T19:18:32.358987Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = pd.DataFrame({'file': os.listdir('/kaggle/files/images/train')})\n\ncategories = []\nfor i in os.listdir('/kaggle/files/images/train'):\n    if 'dog' in i:\n        categories.append(1)\n    else:\n        categories.append(0)\n        \ntrain['categories'] = categories\n\ntest = pd.DataFrame({'file': os.listdir('/kaggle/files/images/test1')})","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:32.363461Z","iopub.execute_input":"2021-12-14T19:18:32.363676Z","iopub.status.idle":"2021-12-14T19:18:32.436717Z","shell.execute_reply.started":"2021-12-14T19:18:32.363650Z","shell.execute_reply":"2021-12-14T19:18:32.435967Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### 3 - See an example ","metadata":{}},{"cell_type":"code","source":"def example_im(index):\n    '''\n    Function to display an example image.\n    \n    index -- which image in the training set. \n    '''\n    im = plt.imread('/kaggle/files/images/train/'+str(train['file'][index]))\n\n    print(type(im))\n    print(im.shape)\n    print(type(im.shape))\n    \n    plt.imshow(im)\n    plt.axis('off')\n    \nexample_im(1)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:32.438066Z","iopub.execute_input":"2021-12-14T19:18:32.438316Z","iopub.status.idle":"2021-12-14T19:18:32.627075Z","shell.execute_reply.started":"2021-12-14T19:18:32.438281Z","shell.execute_reply":"2021-12-14T19:18:32.625488Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### 4 - Data Preparation ","metadata":{}},{"cell_type":"code","source":"train['categories'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:32.628234Z","iopub.execute_input":"2021-12-14T19:18:32.628526Z","iopub.status.idle":"2021-12-14T19:18:32.640293Z","shell.execute_reply.started":"2021-12-14T19:18:32.628489Z","shell.execute_reply":"2021-12-14T19:18:32.639366Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"For our data, we have same number of cats and dogs and training data.","metadata":{}},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:32.642374Z","iopub.execute_input":"2021-12-14T19:18:32.642759Z","iopub.status.idle":"2021-12-14T19:18:32.653452Z","shell.execute_reply.started":"2021-12-14T19:18:32.642715Z","shell.execute_reply":"2021-12-14T19:18:32.652619Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"The numeric varaible in `categories` columns is mapped to string for later image generation\n\nThe training data is not a particularly small dataset so we can use `10%` of its data as a `cross validation set`, and `random_state` is set to be 0 for reproductivity.","metadata":{}},{"cell_type":"code","source":"train['categories'] = train['categories'].replace({0: 'cat', 1: 'dog'})\ntrain_set, val_set = train_test_split(train, test_size=0.1, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:32.654873Z","iopub.execute_input":"2021-12-14T19:18:32.655800Z","iopub.status.idle":"2021-12-14T19:18:32.671523Z","shell.execute_reply.started":"2021-12-14T19:18:32.655757Z","shell.execute_reply":"2021-12-14T19:18:32.670764Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_gen_scaled = ImageDataGenerator(rescale=1./255)\nval_gen_scaled = ImageDataGenerator(rescale=1./255)\n\nbatch_size = 64\n\ntrain_generator_scaled = train_gen_scaled.flow_from_dataframe(\n    dataframe = train_set,\n    directory = destination + '/train/', # file path format\n    x_col = 'file',\n    y_col = 'categories',\n    class_mode = 'categorical',\n    target_size = (224,224),\n    batch_size = batch_size\n)\n\n\nvalidation_generator_scaled = val_gen_scaled.flow_from_dataframe(\n    dataframe = val_set,\n    directory = destination + '/train/',\n    x_col = 'file',\n    y_col = 'categories',\n    class_mode = 'categorical',\n    target_size = (224,224),\n    batch_size = batch_size\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:32.672824Z","iopub.execute_input":"2021-12-14T19:18:32.673214Z","iopub.status.idle":"2021-12-14T19:18:33.108712Z","shell.execute_reply.started":"2021-12-14T19:18:32.673169Z","shell.execute_reply":"2021-12-14T19:18:33.107970Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def mini_batch_example_plot(df):\n\n    example_generator = train_gen_scaled.flow_from_dataframe(\n        dataframe = df,\n        directory = destination + '/train/',\n        x_col = 'file',\n        y_col = 'categories',\n        class_mode = 'categorical',\n        target_size = (224,224)\n    )\n    \n    fig, ax  = plt.subplots(2,4,figsize=(12, 12))\n    ax = ax.flatten()\n    \n    for i in range(8):\n        X, Y = next(example_generator)\n        image = X[0]\n        ax[i].imshow(image)\n        ax[i].axis('off')\n    \n    \nmini_batch_example_plot(train_set)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:33.112448Z","iopub.execute_input":"2021-12-14T19:18:33.113239Z","iopub.status.idle":"2021-12-14T19:18:35.826861Z","shell.execute_reply.started":"2021-12-14T19:18:33.113199Z","shell.execute_reply":"2021-12-14T19:18:35.826138Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### 5 - CNN model construction","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import (\n    BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n)\n\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\n","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:35.830721Z","iopub.execute_input":"2021-12-14T19:18:35.834273Z","iopub.status.idle":"2021-12-14T19:18:35.851492Z","shell.execute_reply.started":"2021-12-14T19:18:35.834229Z","shell.execute_reply":"2021-12-14T19:18:35.850857Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# set constants\n(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS) = (224,224,3)\nIMAGE_SIZE  = (IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_SHAPE = (224,224,3)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:35.853011Z","iopub.execute_input":"2021-12-14T19:18:35.854742Z","iopub.status.idle":"2021-12-14T19:18:37.058982Z","shell.execute_reply.started":"2021-12-14T19:18:35.854705Z","shell.execute_reply":"2021-12-14T19:18:37.058046Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def shallow_CNN_Model(image_shape, augmentation = False):\n    '''\n    This creates a shallow CNN model, the structure uses the idea from VGG-16\n    '''\n    if (augmentation == True):\n        model = tf.keras.Sequential([RandomFlip(\"horizontal\",input_shape = image_shape),\n                   RandomRotation(0.1)])\n    else: \n        model = tf.keras.Sequential()\n\n    model.add(Conv2D(32, (3, 3), activation='relu', input_shape = image_shape))\n    model.add(Conv2D(32, (3, 3), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation='softmax'))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:37.060397Z","iopub.execute_input":"2021-12-14T19:18:37.060686Z","iopub.status.idle":"2021-12-14T19:18:37.093749Z","shell.execute_reply.started":"2021-12-14T19:18:37.060650Z","shell.execute_reply":"2021-12-14T19:18:37.092903Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = shallow_CNN_Model(IMAGE_SHAPE)\nmodel_augmented = shallow_CNN_Model(IMAGE_SHAPE,True)\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_augmented.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:37.095059Z","iopub.execute_input":"2021-12-14T19:18:37.095431Z","iopub.status.idle":"2021-12-14T19:18:40.214009Z","shell.execute_reply.started":"2021-12-14T19:18:37.095390Z","shell.execute_reply":"2021-12-14T19:18:40.213294Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### 6 - Early stopping after seeing no decrease in loss over 5 epoches","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nearlystop = EarlyStopping(patience=5)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:40.215413Z","iopub.execute_input":"2021-12-14T19:18:40.215684Z","iopub.status.idle":"2021-12-14T19:18:40.222978Z","shell.execute_reply.started":"2021-12-14T19:18:40.215649Z","shell.execute_reply":"2021-12-14T19:18:40.222417Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def model_fitting(model, train_generator, val_generator, callbacks, epochs):\n    '''\n    This is a function used to fit generator, with customized input \n    model, callbacks, and epochs. \n    '''\n    return model.fit_generator(\n        train_generator, \n        epochs = epochs,\n        validation_data = val_generator,\n        validation_steps = val_set.shape[0]//64,\n        steps_per_epoch = train_set.shape[0]//64,\n        callbacks = callbacks \n    )\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:40.224552Z","iopub.execute_input":"2021-12-14T19:18:40.224770Z","iopub.status.idle":"2021-12-14T19:18:41.230234Z","shell.execute_reply.started":"2021-12-14T19:18:40.224743Z","shell.execute_reply":"2021-12-14T19:18:41.229372Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"In previous test, the dataset not being augmented performs worse than augmented dataset on validation set, showing a sign of overfitting in training set.  ","metadata":{}},{"cell_type":"code","source":"history_epoch50 = model_fitting(model,train_generator_scaled, validation_generator_scaled, [earlystop], epochs = 50)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:18:41.231569Z","iopub.execute_input":"2021-12-14T19:18:41.232009Z","iopub.status.idle":"2021-12-14T19:57:51.379364Z","shell.execute_reply.started":"2021-12-14T19:18:41.231969Z","shell.execute_reply":"2021-12-14T19:57:51.378498Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"history_epoch50_augmented = model_fitting(model_augmented,train_generator_scaled, validation_generator_scaled, [earlystop], epochs = 50)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T19:57:51.381324Z","iopub.execute_input":"2021-12-14T19:57:51.381592Z","iopub.status.idle":"2021-12-14T20:42:47.655656Z","shell.execute_reply.started":"2021-12-14T19:57:51.381555Z","shell.execute_reply":"2021-12-14T20:42:47.654842Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model_augmented.save_weights('model_augmented_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-14T20:42:47.657063Z","iopub.execute_input":"2021-12-14T20:42:47.657299Z","iopub.status.idle":"2021-12-14T20:42:47.997050Z","shell.execute_reply.started":"2021-12-14T20:42:47.657266Z","shell.execute_reply":"2021-12-14T20:42:47.996152Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\ndef plotting_loss(history,upper_bound):\n\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 4))\n    \n    ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n    ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n    ax1.set_xticks(np.arange(1, upper_bound, 1))\n    ax1.set_yticks(np.arange(0, 1, 0.1))\n\n    ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n    ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n    ax2.set_xticks(np.arange(1, upper_bound, 1))\n\n    legend = plt.legend(loc='best', shadow=True)\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-14T20:42:47.998450Z","iopub.execute_input":"2021-12-14T20:42:47.998741Z","iopub.status.idle":"2021-12-14T20:43:22.704359Z","shell.execute_reply.started":"2021-12-14T20:42:47.998704Z","shell.execute_reply":"2021-12-14T20:43:22.703498Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"plotting_loss(history_epoch50, 50)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T20:43:22.705858Z","iopub.execute_input":"2021-12-14T20:43:22.706234Z","iopub.status.idle":"2021-12-14T20:43:23.503236Z","shell.execute_reply.started":"2021-12-14T20:43:22.706195Z","shell.execute_reply":"2021-12-14T20:43:23.502482Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"plotting_loss(history_epoch50_augmented, 40)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T20:43:23.504787Z","iopub.execute_input":"2021-12-14T20:43:23.505093Z","iopub.status.idle":"2021-12-14T20:43:24.143119Z","shell.execute_reply.started":"2021-12-14T20:43:23.505057Z","shell.execute_reply":"2021-12-14T20:43:24.142439Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Using functional API for easier operation on last few layers for transfer learning.","metadata":{}},{"cell_type":"code","source":"def data_augmenter():\n    '''\n    Create a Sequential model composed of 2 layers\n    Returns:\n        tf.keras.Sequential\n    '''\n    ### START CODE HERE\n    data_augmentation = tf.keras.Sequential()\n    data_augmentation.add(RandomFlip('horizontal'))\n    data_augmentation.add(RandomRotation(0.2))\n    ### END CODE HERE\n    \n    return data_augmentation","metadata":{"execution":{"iopub.status.busy":"2021-12-14T20:43:24.144724Z","iopub.execute_input":"2021-12-14T20:43:24.145201Z","iopub.status.idle":"2021-12-14T20:43:24.150403Z","shell.execute_reply.started":"2021-12-14T20:43:24.145164Z","shell.execute_reply":"2021-12-14T20:43:24.149572Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_gen = ImageDataGenerator()\nval_gen = ImageDataGenerator()\nbatch_size = 64\n\ntrain_generator = train_gen.flow_from_dataframe(\n    dataframe = train_set,\n    directory = destination + '/train/', # file path format\n    x_col = 'file',\n    y_col = 'categories',\n    class_mode = 'categorical',\n    target_size = (224,224),\n    batch_size = batch_size\n)\n\n\nvalidation_generator = val_gen.flow_from_dataframe(\n    dataframe = val_set,\n    directory = destination + '/train/',\n    x_col = 'file',\n    y_col = 'categories',\n    class_mode = 'categorical',\n    target_size = (224,224),\n    batch_size = batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T20:43:24.151595Z","iopub.execute_input":"2021-12-14T20:43:24.151896Z","iopub.status.idle":"2021-12-14T20:43:24.413728Z","shell.execute_reply.started":"2021-12-14T20:43:24.151860Z","shell.execute_reply":"2021-12-14T20:43:24.412986Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"input_shape = (224,224, 3)\n\ndef transfer_learning(model,image_shape=input_shape, data_augmentation=data_augmenter()):\n    ''' Define a tf.keras model for binary classification out of the MobileNetV2 model\n    Arguments:\n        image_shape -- Image width and height\n        data_augmentation -- data augmentation function\n\n    Returns:\n        tf.keras.model\n    '''\n    if model == 'MobileNetV2':\n        base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n                                                       include_top=False, \n                                                       weights='imagenet') # From imageNet\n        preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n        \n        \n    if model == 'VGG':\n        base_model = tf.keras.applications.VGG16(input_shape=input_shape,\n                                                    weights=\"imagenet\", \n                                                    include_top=False)\n        preprocess_input = tf.keras.applications.vgg16.preprocess_input\n        \n        \n    # freeze the base model by making it non trainable\n    base_model.trainable = False\n\n    # create the input layer (Same as the imageNetv2 input size)\n    inputs = tf.keras.Input(shape = input_shape) \n    \n    # apply data augmentation to the inputs\n    x = data_augmentation(inputs)\n    \n    # data preprocessing using the same weights the model was trained on\n    x = preprocess_input(x) \n    \n    # set training to False to avoid keeping track of statistics in the batch norm layer\n    x = base_model(x, training=False) \n    \n    # add the new Binary classification layers\n    # use global avg pooling to summarize the info in each channel\n    x = tfl.GlobalAveragePooling2D()(x) \n    # include dropout with probability of 0.2 to avoid overfitting\n    x = tfl.Dropout(0.2)(x)\n        \n    # use a prediction layer with one neuron (as a binary classifier only needs one)\n    outputs = tfl.Dense(units = 2)(x)\n\n    new_model = tf.keras.Model(inputs, outputs)\n    \n    return new_model\n","metadata":{"execution":{"iopub.status.busy":"2021-12-14T20:43:24.415081Z","iopub.execute_input":"2021-12-14T20:43:24.415506Z","iopub.status.idle":"2021-12-14T20:43:24.432490Z","shell.execute_reply.started":"2021-12-14T20:43:24.415466Z","shell.execute_reply":"2021-12-14T20:43:24.431787Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model_trans_VGG = transfer_learning('VGG',(224,224,3), data_augmenter())\nbase_learning_rate = 0.001\nmodel_trans_VGG.compile(\n              #optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              optimizer = 'adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel_trans_Mobile = transfer_learning('MobileNetV2',(224,224,3), data_augmenter())\nbase_learning_rate = 0.001\nmodel_trans_Mobile.compile(\n                #optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n                optimizer = 'adam',\n                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n                metrics=['accuracy'])\n\nmodel_trans_VGG.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T20:43:24.434045Z","iopub.execute_input":"2021-12-14T20:43:24.434292Z","iopub.status.idle":"2021-12-14T20:43:27.370436Z","shell.execute_reply.started":"2021-12-14T20:43:24.434257Z","shell.execute_reply":"2021-12-14T20:43:27.369666Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model_trans_Mobile.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T20:43:27.371756Z","iopub.execute_input":"2021-12-14T20:43:27.372028Z","iopub.status.idle":"2021-12-14T20:43:27.391139Z","shell.execute_reply.started":"2021-12-14T20:43:27.371990Z","shell.execute_reply":"2021-12-14T20:43:27.390479Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"history_trans_VGG = model_fitting(model_trans_VGG,train_generator, validation_generator, [earlystop], epochs = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T20:43:27.394977Z","iopub.execute_input":"2021-12-14T20:43:27.395167Z","iopub.status.idle":"2021-12-14T21:13:19.647900Z","shell.execute_reply.started":"2021-12-14T20:43:27.395143Z","shell.execute_reply":"2021-12-14T21:13:19.647010Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"history_trans_Mobile = model_fitting(model_trans_Mobile,train_generator, validation_generator, [earlystop], epochs = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T21:13:19.651626Z","iopub.execute_input":"2021-12-14T21:13:19.651854Z","iopub.status.idle":"2021-12-14T21:31:22.771784Z","shell.execute_reply.started":"2021-12-14T21:13:19.651825Z","shell.execute_reply":"2021-12-14T21:31:22.770959Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"plotting_loss(history_trans_VGG, 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T21:31:22.775959Z","iopub.execute_input":"2021-12-14T21:31:22.776511Z","iopub.status.idle":"2021-12-14T21:32:11.326078Z","shell.execute_reply.started":"2021-12-14T21:31:22.776467Z","shell.execute_reply":"2021-12-14T21:32:11.325408Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"plotting_loss(history_trans_Mobile, 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T21:32:11.327728Z","iopub.execute_input":"2021-12-14T21:32:11.328286Z","iopub.status.idle":"2021-12-14T21:32:11.735334Z","shell.execute_reply.started":"2021-12-14T21:32:11.328230Z","shell.execute_reply":"2021-12-14T21:32:11.734474Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}